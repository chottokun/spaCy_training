# spaCy_training
spaCyã®ä½¿ã„æ–¹ã®ãŠå‹‰å¼·ã€‚  
spaCyã¯è‡ªç„¶è¨€èªå‡¦ç†ã®é“å…·ãŒä¸€æƒã„æƒã£ã¦ã„ã‚‹ã€‚ä¾¿åˆ©ã™ãã‚‹ã®ã§ä½¿ã„ãŸã„ã€‚spaCy3ã‹ã‚‰BERTã‚‚ï¼ˆæ°—è»½ã«ï¼‰ä½¿ãˆã‚‹æ§˜ã«ãªã£ãŸã®ã§ã€ã„ã‚ã‚“ãªãƒ¢ãƒ‡ãƒ«ãŒä½¿ãˆã‚‹æ§˜ã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ã¦ã¿ãŸã€‚

- æ±åŒ—å¤§BERTãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†  
https://github.com/chottokun/spaCy_training/blob/main/Spacy_with_tf_learning01.ipynbã€€ã€€
-----
https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part15.html  
ã‚’å‚è€ƒã«é †ã«å®Ÿæ–½ã—ã¦ã¿ãŸãŒã€æ‰‹é–“å–ã£ãŸã€‚å¤‰æ›´ã—ã¤ã¤å®Ÿè¡Œã€‚  ã€€
å›ºæœ‰è¡¨ç¾ã¾ã§å­¦ç¿’ã¾ã§ã€‚  

- äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ å­¦ç¿’
https://github.com/chottokun/spaCy_training/blob/main/BERT_Further_PRETRAIN_.ipynb  
-----
train.txt ã«è¿½åŠ å­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã•ã›ã¦å­¦ç¿’ã€‚  
ãƒ†ã‚¹ãƒˆã§ã¯ã€ã¾ã lossã¯ä¸‹ãŒã‚Šãã†ã ã£ãŸã€‚æœ¬ç•ªï¼Ÿã§ã¯ã˜ã£ãã‚Šã¨ã‹ãªããƒ»ãƒ»ãƒ»ã€‚  

- MobileBERTï¼ˆJP)ã«è¿½åŠ å­¦ç¿’ã—ã¦ã¿ã‚‹ã€‚


## èª²é¡Œ
tcmalloc: large alloc ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã‚‹ã®ã§ã€Colab
"FutureWarning:" This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py FutureWarning,
ã¸ã®å¯¾å¿œã€‚
https://nikkie-ftnext.hatenablog.com/entry/replace-linebylinetextdataset-datasets-library


